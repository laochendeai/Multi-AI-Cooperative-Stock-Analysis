#!/usr/bin/env python3
"""
æ™ºèƒ½ä»£ç ä»“åº“æ¸…ç†å·¥å…·
ä¸“ä¸šçš„ä»£ç ä»“åº“ç®¡ç†åŠ©æ‰‹
"""

import os
import shutil
import subprocess
import json
from pathlib import Path
from datetime import datetime, timedelta
import re

class IntelligentRepoCleanup:
    def __init__(self, repo_path="."):
        self.repo_path = Path(repo_path)
        self.backup_dir = self.repo_path / "backup_temp"
        self.cleanup_log = []
        self.preserved_files = []
        self.cleaned_files = []
        
        # æ ¸å¿ƒæ–‡ä»¶æ¨¡å¼
        self.core_patterns = {
            'source_dirs': ['src/', 'lib/', 'core/', 'tradingagents/', 'ui_modules/'],
            'config_files': ['package.json', 'requirements.txt', 'Dockerfile', '.env.example', 
                           'config/', 'pyproject.toml', 'setup.py', 'setup.cfg'],
            'docs': ['README.md', 'LICENSE', 'CHANGELOG.md', 'docs/', 'RELEASE_NOTES.md'],
            'git_meta': ['.gitignore', '.gitattributes', '.github/']
        }
        
        # æ¸…ç†ç›®æ ‡æ¨¡å¼
        self.cleanup_patterns = {
            'test_files': ['tests/', '__test__/', '*test*.py', '*.spec.js', '*_test.py', 
                          'test_*.py', 'minimal_test_app.py', 'debug_app.py'],
            'ai_docs': ['*_REPORT.md', '*_SUMMARY.md', '*_GUIDE.md', '*_explanation.txt',
                       '*_FIX_*.md', '*_COMPLETION_*.md', '*_OPTIMIZATION_*.md'],
            'dev_cache': ['.vscode/', '.idea/', '__pycache__/', '*.pyc', '.pytest_cache/',
                         'node_modules/', '.cache/'],
            'build_artifacts': ['dist/', 'build/', '*.egg-info/', '.tox/', 'coverage/',
                              'htmlcov/', '.coverage'],
            'temp_files': ['*.tmp', '*.temp', '*.log', '*.bak', '*~', '.DS_Store'],
            'backup_files': ['backups/', '*_backup_*.py', '*_backup_*.txt']
        }
    
    def get_repo_size(self):
        """è·å–ä»“åº“å¤§å°"""
        try:
            result = subprocess.run(['du', '-sh', '.'], capture_output=True, text=True, cwd=self.repo_path)
            if result.returncode == 0:
                return result.stdout.split()[0]
        except:
            pass
        return "Unknown"
    
    def is_recently_modified(self, file_path, days=3):
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨æœ€è¿‘å‡ å¤©å†…ä¿®æ”¹è¿‡"""
        try:
            mtime = datetime.fromtimestamp(file_path.stat().st_mtime)
            return datetime.now() - mtime < timedelta(days=days)
        except:
            return False
    
    def should_preserve_file(self, file_path):
        """åˆ¤æ–­æ–‡ä»¶æ˜¯å¦åº”è¯¥ä¿ç•™"""
        path_str = str(file_path)
        
        # ä¿ç•™ç”¨æˆ·è‡ªå®šä¹‰æ–‡ä»¶
        if 'user_custom' in path_str.lower():
            return True, "ç”¨æˆ·è‡ªå®šä¹‰æ–‡ä»¶"
        
        # ä¿ç•™æ ¸å¿ƒæºä»£ç ç›®å½•
        for pattern in self.core_patterns['source_dirs']:
            if path_str.startswith(pattern) or f"/{pattern}" in path_str:
                return True, "æ ¸å¿ƒæºä»£ç "
        
        # ä¿ç•™å…³é”®é…ç½®æ–‡ä»¶
        for pattern in self.core_patterns['config_files']:
            if pattern in path_str or file_path.name == pattern:
                return True, "å…³é”®é…ç½®æ–‡ä»¶"
        
        # ä¿ç•™å¿…è¦æ–‡æ¡£
        for pattern in self.core_patterns['docs']:
            if pattern in path_str or file_path.name == pattern:
                return True, "å¿…è¦æ–‡æ¡£"
        
        # ä¿ç•™gitå…ƒæ•°æ®
        for pattern in self.core_patterns['git_meta']:
            if pattern in path_str:
                return True, "Gitå…ƒæ•°æ®"
        
        # ä¿ç•™ä¸»è¦åº”ç”¨æ–‡ä»¶
        if file_path.name in ['final_integrated_app.py', 'app_enhanced.py']:
            return True, "ä¸»è¦åº”ç”¨æ–‡ä»¶"
        
        return False, ""
    
    def should_cleanup_file(self, file_path):
        """åˆ¤æ–­æ–‡ä»¶æ˜¯å¦åº”è¯¥æ¸…ç†"""
        path_str = str(file_path)
        
        # æ£€æŸ¥å„ç§æ¸…ç†æ¨¡å¼
        for category, patterns in self.cleanup_patterns.items():
            for pattern in patterns:
                if self.match_pattern(path_str, pattern):
                    return True, category
        
        return False, ""
    
    def match_pattern(self, path_str, pattern):
        """åŒ¹é…æ–‡ä»¶æ¨¡å¼"""
        if pattern.endswith('/'):
            return pattern[:-1] in path_str.split('/')
        elif '*' in pattern:
            import fnmatch
            return fnmatch.fnmatch(os.path.basename(path_str), pattern)
        else:
            return pattern in path_str
    
    def backup_recent_files(self, file_path):
        """å¤‡ä»½æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶"""
        if self.is_recently_modified(file_path):
            self.backup_dir.mkdir(exist_ok=True)
            backup_path = self.backup_dir / file_path.name
            try:
                if file_path.is_file():
                    shutil.copy2(file_path, backup_path)
                elif file_path.is_dir():
                    shutil.copytree(file_path, backup_path, dirs_exist_ok=True)
                return True
            except Exception as e:
                print(f"å¤‡ä»½å¤±è´¥ {file_path}: {e}")
        return False
    
    def analyze_files(self):
        """åˆ†ææ–‡ä»¶å¹¶åˆ†ç±»"""
        to_preserve = []
        to_cleanup = []
        
        for root, dirs, files in os.walk(self.repo_path):
            # è·³è¿‡.gitç›®å½•
            if '.git' in dirs:
                dirs.remove('.git')
            
            root_path = Path(root)
            
            # æ£€æŸ¥ç›®å½•
            for dir_name in dirs[:]:  # ä½¿ç”¨åˆ‡ç‰‡å¤åˆ¶é¿å…ä¿®æ”¹è¿­ä»£ä¸­çš„åˆ—è¡¨
                dir_path = root_path / dir_name
                should_preserve, reason = self.should_preserve_file(dir_path)
                should_cleanup, cleanup_reason = self.should_cleanup_file(dir_path)
                
                if should_preserve:
                    to_preserve.append((dir_path, reason))
                elif should_cleanup:
                    to_cleanup.append((dir_path, cleanup_reason))
            
            # æ£€æŸ¥æ–‡ä»¶
            for file_name in files:
                file_path = root_path / file_name
                should_preserve, reason = self.should_preserve_file(file_path)
                should_cleanup, cleanup_reason = self.should_cleanup_file(file_path)
                
                if should_preserve:
                    to_preserve.append((file_path, reason))
                elif should_cleanup:
                    to_cleanup.append((file_path, cleanup_reason))
        
        return to_preserve, to_cleanup
    
    def preview_cleanup(self):
        """é¢„è§ˆæ¸…ç†æ“ä½œ"""
        print("ğŸ” åˆ†æé¡¹ç›®æ–‡ä»¶ç»“æ„...")
        to_preserve, to_cleanup = self.analyze_files()
        
        print(f"\nğŸ“Š åˆ†æç»“æœ:")
        print(f"  ä¿ç•™æ–‡ä»¶: {len(to_preserve)} ä¸ª")
        print(f"  æ¸…ç†æ–‡ä»¶: {len(to_cleanup)} ä¸ª")
        
        print(f"\nâœ… å°†ä¿ç•™çš„æ ¸å¿ƒæ–‡ä»¶:")
        for file_path, reason in to_preserve[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
            print(f"  ğŸ“ {file_path} ({reason})")
        if len(to_preserve) > 10:
            print(f"  ... è¿˜æœ‰ {len(to_preserve) - 10} ä¸ªæ–‡ä»¶")
        
        print(f"\nğŸ—‘ï¸ å°†æ¸…ç†çš„æ–‡ä»¶:")
        cleanup_by_category = {}
        for file_path, category in to_cleanup:
            if category not in cleanup_by_category:
                cleanup_by_category[category] = []
            cleanup_by_category[category].append(file_path)
        
        for category, files in cleanup_by_category.items():
            print(f"  ğŸ“‚ {category}: {len(files)} ä¸ªæ–‡ä»¶")
            for file_path in files[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                print(f"    ğŸ—‘ï¸ {file_path}")
            if len(files) > 3:
                print(f"    ... è¿˜æœ‰ {len(files) - 3} ä¸ªæ–‡ä»¶")
        
        return to_preserve, to_cleanup

    def execute_cleanup(self, to_cleanup, confirm=True):
        """æ‰§è¡Œæ¸…ç†æ“ä½œ"""
        if confirm:
            response = input(f"\nâš ï¸ ç¡®è®¤æ¸…ç† {len(to_cleanup)} ä¸ªæ–‡ä»¶/ç›®å½•? (y/N): ")
            if response.lower() != 'y':
                print("âŒ æ¸…ç†æ“ä½œå·²å–æ¶ˆ")
                return False

        print("\nğŸ”„ å¼€å§‹æ¸…ç†æ“ä½œ...")

        # åˆ›å»ºå¤‡ä»½ç›®å½•
        self.backup_dir.mkdir(exist_ok=True)

        cleaned_count = 0
        backed_up_count = 0

        for file_path, category in to_cleanup:
            try:
                # å¤‡ä»½æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶
                if self.backup_recent_files(file_path):
                    backed_up_count += 1
                    print(f"ğŸ’¾ å·²å¤‡ä»½: {file_path}")

                # ä½¿ç”¨git rmåˆ é™¤å·²è·Ÿè¸ªçš„æ–‡ä»¶
                if file_path.exists():
                    try:
                        result = subprocess.run(['git', 'rm', '-rf', str(file_path)],
                                              capture_output=True, text=True, cwd=self.repo_path)
                        if result.returncode == 0:
                            print(f"ğŸ—‘ï¸ Gitåˆ é™¤: {file_path}")
                        else:
                            # å¦‚æœgit rmå¤±è´¥ï¼Œä½¿ç”¨ç³»ç»Ÿåˆ é™¤
                            if file_path.is_file():
                                file_path.unlink()
                            elif file_path.is_dir():
                                shutil.rmtree(file_path)
                            print(f"ğŸ—‘ï¸ ç³»ç»Ÿåˆ é™¤: {file_path}")
                    except Exception as e:
                        print(f"âŒ åˆ é™¤å¤±è´¥ {file_path}: {e}")
                        continue

                self.cleaned_files.append((file_path, category))
                cleaned_count += 1

            except Exception as e:
                print(f"âŒ å¤„ç†å¤±è´¥ {file_path}: {e}")

        print(f"\nâœ… æ¸…ç†å®Œæˆ!")
        print(f"  ğŸ—‘ï¸ å·²æ¸…ç†: {cleaned_count} ä¸ªæ–‡ä»¶/ç›®å½•")
        print(f"  ğŸ’¾ å·²å¤‡ä»½: {backed_up_count} ä¸ªæœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶")

        return True

    def generate_cleanup_report(self):
        """ç”Ÿæˆæ¸…ç†æŠ¥å‘Š"""
        report_path = self.repo_path / "cleaned_files.log"

        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# TradingAgents ä»“åº“æ¸…ç†æŠ¥å‘Š\n")
            f.write(f"æ¸…ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

            f.write("## æ¸…ç†ç»Ÿè®¡\n")
            f.write(f"æ€»æ¸…ç†æ–‡ä»¶æ•°: {len(self.cleaned_files)}\n\n")

            # æŒ‰ç±»åˆ«ç»Ÿè®¡
            category_stats = {}
            for _, category in self.cleaned_files:
                category_stats[category] = category_stats.get(category, 0) + 1

            f.write("## æŒ‰ç±»åˆ«ç»Ÿè®¡\n")
            for category, count in category_stats.items():
                f.write(f"- {category}: {count} ä¸ªæ–‡ä»¶\n")

            f.write("\n## æ¸…ç†çš„æ–‡ä»¶åˆ—è¡¨\n")
            for file_path, category in self.cleaned_files:
                f.write(f"- [{category}] {file_path}\n")

        print(f"ğŸ“‹ æ¸…ç†æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
        return report_path

if __name__ == "__main__":
    cleanup = IntelligentRepoCleanup()

    print("ğŸ¤– TradingAgents æ™ºèƒ½ä»“åº“æ¸…ç†å·¥å…·")
    print("=" * 50)

    # è·å–æ¸…ç†å‰å¤§å°
    initial_size = cleanup.get_repo_size()
    print(f"ğŸ“Š æ¸…ç†å‰ä»“åº“å¤§å°: {initial_size}")

    # é¢„è§ˆæ¸…ç†
    to_preserve, to_cleanup = cleanup.preview_cleanup()

    # æ‰§è¡Œæ¸…ç†
    if cleanup.execute_cleanup(to_cleanup):
        # ç”ŸæˆæŠ¥å‘Š
        cleanup.generate_cleanup_report()

        # è·å–æ¸…ç†åå¤§å°
        final_size = cleanup.get_repo_size()
        print(f"ğŸ“Š æ¸…ç†åä»“åº“å¤§å°: {final_size}")

        # è®¡ç®—ç²¾ç®€ç‡
        try:
            initial_mb = float(initial_size.replace('M', ''))
            final_mb = float(final_size.replace('M', ''))
            reduction_rate = (initial_mb - final_mb) / initial_mb * 100
            print(f"ğŸ“ˆ ä»“åº“ç²¾ç®€ç‡: {reduction_rate:.1f}%")
        except:
            print("ğŸ“ˆ ä»“åº“ç²¾ç®€ç‡: è®¡ç®—å¤±è´¥")

        print("\nğŸ‰ æ¸…ç†å®Œæˆ! å¯ä»¥ç»§ç»­è¿›è¡Œgitæäº¤æ“ä½œã€‚")
