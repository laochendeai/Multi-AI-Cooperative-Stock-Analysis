#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TradingAgents æ¨¡å‹ç¼“å­˜æ¸…ç†å·¥å…·
æ¸…ç†æŸåçš„sentence-transformersæ¨¡å‹ç¼“å­˜
"""

import os
import sys
import json
import shutil
from datetime import datetime
from pathlib import Path

def find_model_cache_directories():
    """æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„æ¨¡å‹ç¼“å­˜ç›®å½•"""
    cache_dirs = []
    
    # å¸¸è§çš„ç¼“å­˜ç›®å½•ä½ç½®
    possible_dirs = [
        "data/models",
        "models",
        ".cache/torch/sentence_transformers",
        os.path.expanduser("~/.cache/torch/sentence_transformers"),
        os.path.expanduser("~/.cache/huggingface/transformers"),
        "cache/models"
    ]
    
    for dir_path in possible_dirs:
        if os.path.exists(dir_path):
            cache_dirs.append(os.path.abspath(dir_path))
    
    return cache_dirs

def check_json_file_integrity(file_path):
    """æ£€æŸ¥JSONæ–‡ä»¶å®Œæ•´æ€§"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            json.load(f)
        return True
    except (json.JSONDecodeError, UnicodeDecodeError, FileNotFoundError):
        return False
    except Exception:
        return False

def scan_model_cache(cache_dir):
    """æ‰«ææ¨¡å‹ç¼“å­˜ç›®å½•ï¼ŒæŸ¥æ‰¾æŸåçš„æ–‡ä»¶"""
    print(f"ğŸ” æ‰«æç¼“å­˜ç›®å½•: {cache_dir}")
    
    corrupted_models = []
    total_models = 0
    
    if not os.path.exists(cache_dir):
        print(f"   âš ï¸ ç›®å½•ä¸å­˜åœ¨: {cache_dir}")
        return corrupted_models
    
    for item in os.listdir(cache_dir):
        item_path = os.path.join(cache_dir, item)
        
        if os.path.isdir(item_path):
            total_models += 1
            print(f"   ğŸ“ æ£€æŸ¥æ¨¡å‹: {item}")
            
            # æ£€æŸ¥å…³é”®æ–‡ä»¶
            critical_files = ['config.json', 'tokenizer.json', 'pytorch_model.bin']
            corrupted_files = []
            
            for file_name in critical_files:
                file_path = os.path.join(item_path, file_name)
                if os.path.exists(file_path):
                    if file_name.endswith('.json'):
                        if not check_json_file_integrity(file_path):
                            corrupted_files.append(file_name)
                            print(f"      âŒ æŸåæ–‡ä»¶: {file_name}")
                    else:
                        # æ£€æŸ¥äºŒè¿›åˆ¶æ–‡ä»¶å¤§å°
                        try:
                            size = os.path.getsize(file_path)
                            if size < 1024:  # å°äº1KBå¯èƒ½æ˜¯æŸåçš„
                                corrupted_files.append(file_name)
                                print(f"      âŒ å¯ç–‘æ–‡ä»¶: {file_name} (å¤§å°: {size} bytes)")
                        except:
                            corrupted_files.append(file_name)
            
            if corrupted_files:
                corrupted_models.append({
                    'model_name': item,
                    'model_path': item_path,
                    'corrupted_files': corrupted_files
                })
                print(f"      ğŸš¨ æ¨¡å‹æŸå: {len(corrupted_files)}ä¸ªæ–‡ä»¶")
            else:
                print(f"      âœ… æ¨¡å‹å®Œæ•´")
    
    print(f"   ğŸ“Š æ‰«æå®Œæˆ: {total_models}ä¸ªæ¨¡å‹ï¼Œ{len(corrupted_models)}ä¸ªæŸå")
    return corrupted_models

def clean_corrupted_models(corrupted_models, auto_confirm=False):
    """æ¸…ç†æŸåçš„æ¨¡å‹"""
    if not corrupted_models:
        print("âœ… æ²¡æœ‰å‘ç°æŸåçš„æ¨¡å‹ç¼“å­˜")
        return
    
    print(f"\nğŸ§¹ å‘ç° {len(corrupted_models)} ä¸ªæŸåçš„æ¨¡å‹ç¼“å­˜:")
    
    for i, model_info in enumerate(corrupted_models, 1):
        print(f"\n{i}. æ¨¡å‹: {model_info['model_name']}")
        print(f"   è·¯å¾„: {model_info['model_path']}")
        print(f"   æŸåæ–‡ä»¶: {', '.join(model_info['corrupted_files'])}")
        
        # è®¡ç®—ç›®å½•å¤§å°
        try:
            total_size = sum(
                os.path.getsize(os.path.join(dirpath, filename))
                for dirpath, dirnames, filenames in os.walk(model_info['model_path'])
                for filename in filenames
            )
            size_mb = total_size / (1024 * 1024)
            print(f"   å¤§å°: {size_mb:.1f} MB")
        except:
            print(f"   å¤§å°: æ— æ³•è®¡ç®—")
    
    if not auto_confirm:
        print(f"\nâ“ æ˜¯å¦æ¸…ç†è¿™äº›æŸåçš„æ¨¡å‹ç¼“å­˜ï¼Ÿ")
        print("   è¾“å…¥ 'y' æˆ– 'yes' ç¡®è®¤æ¸…ç†")
        print("   è¾“å…¥ 'n' æˆ– 'no' å–æ¶ˆæ“ä½œ")
        
        choice = input("è¯·é€‰æ‹©: ").lower().strip()
        if choice not in ['y', 'yes', 'æ˜¯', 'ç¡®è®¤']:
            print("âŒ æ“ä½œå·²å–æ¶ˆ")
            return
    
    # æ‰§è¡Œæ¸…ç†
    cleaned_count = 0
    total_size_freed = 0
    
    for model_info in corrupted_models:
        try:
            # è®¡ç®—é‡Šæ”¾çš„ç©ºé—´
            try:
                model_size = sum(
                    os.path.getsize(os.path.join(dirpath, filename))
                    for dirpath, dirnames, filenames in os.walk(model_info['model_path'])
                    for filename in filenames
                )
                total_size_freed += model_size
            except:
                pass
            
            # åˆ é™¤æ¨¡å‹ç›®å½•
            shutil.rmtree(model_info['model_path'])
            print(f"   âœ… å·²æ¸…ç†: {model_info['model_name']}")
            cleaned_count += 1
            
        except Exception as e:
            print(f"   âŒ æ¸…ç†å¤±è´¥: {model_info['model_name']} - {e}")
    
    size_freed_mb = total_size_freed / (1024 * 1024)
    print(f"\nğŸ‰ æ¸…ç†å®Œæˆ!")
    print(f"   æ¸…ç†æ¨¡å‹æ•°: {cleaned_count}/{len(corrupted_models)}")
    print(f"   é‡Šæ”¾ç©ºé—´: {size_freed_mb:.1f} MB")

def backup_model_list(cache_dirs):
    """å¤‡ä»½æ¨¡å‹åˆ—è¡¨"""
    try:
        backup_file = f"model_cache_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        
        with open(backup_file, 'w', encoding='utf-8') as f:
            f.write(f"TradingAgents æ¨¡å‹ç¼“å­˜å¤‡ä»½\n")
            f.write(f"å¤‡ä»½æ—¶é—´: {datetime.now()}\n")
            f.write("=" * 50 + "\n\n")
            
            for cache_dir in cache_dirs:
                f.write(f"ç¼“å­˜ç›®å½•: {cache_dir}\n")
                if os.path.exists(cache_dir):
                    for item in os.listdir(cache_dir):
                        item_path = os.path.join(cache_dir, item)
                        if os.path.isdir(item_path):
                            try:
                                size = sum(
                                    os.path.getsize(os.path.join(dirpath, filename))
                                    for dirpath, dirnames, filenames in os.walk(item_path)
                                    for filename in filenames
                                )
                                size_mb = size / (1024 * 1024)
                                f.write(f"  - {item} ({size_mb:.1f} MB)\n")
                            except:
                                f.write(f"  - {item} (å¤§å°æœªçŸ¥)\n")
                f.write("\n")
        
        print(f"ğŸ“‹ æ¨¡å‹åˆ—è¡¨å·²å¤‡ä»½åˆ°: {backup_file}")
        return backup_file
        
    except Exception as e:
        print(f"âš ï¸ å¤‡ä»½å¤±è´¥: {e}")
        return None

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ§¹ TradingAgents æ¨¡å‹ç¼“å­˜æ¸…ç†å·¥å…·")
    print("=" * 60)
    print(f"ğŸ•’ è¿è¡Œæ—¶é—´: {datetime.now()}")
    print()
    
    # æŸ¥æ‰¾ç¼“å­˜ç›®å½•
    print("ğŸ” æŸ¥æ‰¾æ¨¡å‹ç¼“å­˜ç›®å½•...")
    cache_dirs = find_model_cache_directories()
    
    if not cache_dirs:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•æ¨¡å‹ç¼“å­˜ç›®å½•")
        print("ğŸ’¡ å¯èƒ½çš„åŸå› :")
        print("   â€¢ è¿˜æœªä¸‹è½½è¿‡ä»»ä½•æ¨¡å‹")
        print("   â€¢ æ¨¡å‹ç¼“å­˜åœ¨å…¶ä»–ä½ç½®")
        print("   â€¢ ç¼“å­˜ç›®å½•å·²è¢«æ‰‹åŠ¨åˆ é™¤")
        return
    
    print(f"âœ… æ‰¾åˆ° {len(cache_dirs)} ä¸ªç¼“å­˜ç›®å½•:")
    for cache_dir in cache_dirs:
        print(f"   ğŸ“ {cache_dir}")
    
    # å¤‡ä»½æ¨¡å‹åˆ—è¡¨
    print(f"\nğŸ“‹ å¤‡ä»½å½“å‰æ¨¡å‹åˆ—è¡¨...")
    backup_file = backup_model_list(cache_dirs)
    
    # æ‰«ææŸåçš„æ¨¡å‹
    print(f"\nğŸ” æ‰«ææŸåçš„æ¨¡å‹ç¼“å­˜...")
    all_corrupted_models = []
    
    for cache_dir in cache_dirs:
        corrupted_models = scan_model_cache(cache_dir)
        all_corrupted_models.extend(corrupted_models)
    
    # æ¸…ç†æŸåçš„æ¨¡å‹
    if all_corrupted_models:
        clean_corrupted_models(all_corrupted_models)
    else:
        print("âœ… æ‰€æœ‰æ¨¡å‹ç¼“å­˜éƒ½å®Œæ•´ï¼Œæ— éœ€æ¸…ç†")
    
    print(f"\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
    print("   â€¢ å®šæœŸè¿è¡Œæ­¤å·¥å…·æ¸…ç†æŸåç¼“å­˜")
    print("   â€¢ ç¡®ä¿ç½‘ç»œè¿æ¥ç¨³å®šæ—¶ä¸‹è½½æ¨¡å‹")
    print("   â€¢ å¦‚æœç»å¸¸å‡ºç°æŸåï¼Œè€ƒè™‘æ›´æ¢ç¼“å­˜ç›®å½•")
    print("   â€¢ å¤‡ä»½æ–‡ä»¶å¯ç”¨äºæ¢å¤æ¨¡å‹åˆ—è¡¨")
    
    if backup_file:
        print(f"   â€¢ å¤‡ä»½æ–‡ä»¶: {backup_file}")

if __name__ == "__main__":
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    auto_confirm = "--auto" in sys.argv or "-y" in sys.argv
    
    if auto_confirm:
        print("ğŸ¤– è‡ªåŠ¨æ¨¡å¼ï¼šå°†è‡ªåŠ¨æ¸…ç†æŸåçš„ç¼“å­˜")
    
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâŒ æ“ä½œè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
